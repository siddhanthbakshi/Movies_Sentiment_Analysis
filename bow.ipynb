{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 51,
      "metadata": {
        "id": "IeGhiSsGS3pM"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "from sklearn.feature_extraction.text import CountVectorizer\n",
        "import nltk\n",
        "from nltk.corpus import stopwords\n",
        "from nltk.stem import PorterStemmer\n",
        "from sklearn.feature_extraction.text import TfidfVectorizer\n",
        "from sklearn.feature_selection import SelectKBest, mutual_info_classif\n",
        "from nltk.stem import WordNetLemmatizer\n",
        "import re\n",
        "from sklearn.model_selection import cross_val_score, KFold\n",
        "from sklearn.neural_network import MLPClassifier\n",
        "from sklearn.ensemble import RandomForestClassifier\n",
        "from sklearn.metrics import accuracy_score\n",
        "from sklearn.neighbors import KNeighborsClassifier\n",
        "from sklearn.naive_bayes import GaussianNB\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.tree import DecisionTreeClassifier, plot_tree\n",
        "import numpy as np\n",
        "import csv"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 26,
      "metadata": {
        "id": "DrBZZyWvS8Go"
      },
      "outputs": [],
      "source": [
        "train = pd.read_csv('train_yelp_60k.csv')\n",
        "test = pd.read_csv('test_yelp_60k.csv')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 27,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "MfOPVuEVUAeR",
        "outputId": "0dc280e2-d5cf-4a40-b10e-6ac6386a92f9"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-27-2b974a0e1338>:2: FutureWarning: In a future version of pandas all arguments of DataFrame.drop except for the argument 'labels' will be keyword-only.\n",
            "  train_df = train.drop('ID', 1)\n",
            "<ipython-input-27-2b974a0e1338>:3: FutureWarning: In a future version of pandas all arguments of DataFrame.drop except for the argument 'labels' will be keyword-only.\n",
            "  test_df = test.drop('ID', 1)\n"
          ]
        }
      ],
      "source": [
        "# Drop ID from test and train dataframe\n",
        "train_df = train.drop('ID', 1)\n",
        "test_df = test.drop('ID', 1)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 28,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "zwVX-ch9LtsP",
        "outputId": "a96b6ee8-7da5-425d-ab71-29fac6cffc8e"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[nltk_data] Downloading package wordnet to /root/nltk_data...\n",
            "[nltk_data]   Package wordnet is already up-to-date!\n",
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Package stopwords is already up-to-date!\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "metadata": {},
          "execution_count": 28
        }
      ],
      "source": [
        "lemmatizer = WordNetLemmatizer()\n",
        "nltk.download('wordnet')\n",
        "nltk.download('stopwords')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 29,
      "metadata": {
        "id": "wgm6_rSBKTxB"
      },
      "outputs": [],
      "source": [
        "def preprocess(sentence):\n",
        "\n",
        "  sentence = sentence.lower()\n",
        "  sentence = re.sub(r'[^a-zA-Z]', ' ', sentence)\n",
        "\n",
        "  tokens = sentence.split()\n",
        "  lemmatized_tokens = [lemmatizer.lemmatize(token) for token in tokens]\n",
        "\n",
        "  stop_words = set(stopwords.words('english'))\n",
        "  lemmatized_tokens = [word for word in lemmatized_tokens if word not in stop_words]\n",
        "\n",
        "  return ' '.join(lemmatized_tokens)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 30,
      "metadata": {
        "id": "WMsIrv8ALy_k"
      },
      "outputs": [],
      "source": [
        "# apply same preprocessing to train and test dataframes\n",
        "train_df['Text'] = [preprocess(document) for document in train_df['Text']]\n",
        "test_df['Text'] = [preprocess(document) for document in train_df['Text']]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 31,
      "metadata": {
        "id": "Sch6l-dTUb5Q"
      },
      "outputs": [],
      "source": [
        "vectorizer = TfidfVectorizer(max_features=5000)\n",
        "vectorizer.fit(train_df['Text'])\n",
        "X = vectorizer.transform(train_df['Text'])\n",
        "X_test = vectorizer.transform(test_df['Text'])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 32,
      "metadata": {
        "id": "Xyr4n_dHYlDC"
      },
      "outputs": [],
      "source": [
        "columns=vectorizer.get_feature_names_out()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 33,
      "metadata": {
        "id": "IJuGQEEgYMop"
      },
      "outputs": [],
      "source": [
        "vectorizer_train_df = pd.DataFrame(X.toarray(), columns=vectorizer.get_feature_names_out())\n",
        "vectorizer_test_df = pd.DataFrame(X_test.toarray(), columns=vectorizer.get_feature_names_out())"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 34,
      "metadata": {
        "id": "w3-fZXt0Yg0A"
      },
      "outputs": [],
      "source": [
        "vectorizer_df\n",
        "X_train = vectorizer_train_df\n",
        "y_train = train_df['Class']\n",
        "X_test = vectorizer_test_df"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "model = LogisticRegression(max_iter = 1000)\n",
        "model.fit(X_train, y_train)\n",
        "y_pred = model.predict(X_test)"
      ],
      "metadata": {
        "id": "kCvy5dGfcbee"
      },
      "execution_count": 35,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "test = pd.read_csv('test_yelp_60k.csv')\n",
        "ids = test['ID'].to_numpy()\n",
        "data = np.column_stack((ids, y_pred))\n",
        "\n",
        "csv_file_path = 'prediction1.csv'\n",
        "\n",
        "# Write to CSV file\n",
        "with open(csv_file_path, 'w', newline='') as csvfile:\n",
        "    csv_writer = csv.writer(csvfile)\n",
        "    csv_writer.writerow(['ID', 'CLASS'])\n",
        "    csv_writer.writerows(data)"
      ],
      "metadata": {
        "id": "pVPLRcHMh5Nt"
      },
      "execution_count": 52,
      "outputs": []
    }
  ],
  "metadata": {
    "accelerator": "TPU",
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}